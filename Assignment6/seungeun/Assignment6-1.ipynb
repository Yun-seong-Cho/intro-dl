{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 2024 Winter Introduction to Deep Learning\n","### Based on Prof. Oh's Youtube Lecture\n","https://youtube.com/playlist?list=PLvbUC2Zh5oJvByu9KL82bswYT2IKf0K1M\n","\n","> Assignment #6\n","\n","\n","*   Youtube Lecture #23-26\n","*   Written by Seungeun Lee"],"metadata":{"id":"YcXb0XLEvHns"}},{"cell_type":"markdown","source":["## 1. Multi-class Classification w/ Custom ResNet model\n","*     Dataset: CIFAR10\n","\n"],"metadata":{"id":"qM2kM5G7BYZr"}},{"cell_type":"markdown","source":["*    Reference. https://github.com/Justin-A/DeepLearning101/blob/master/4-4_CIFAR_ResNet.ipynb"],"metadata":{"id":"l-eq03krP21I"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import transforms, datasets"],"metadata":{"id":"Q7_JWyTWKoyT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 런타임 - 런타임 유형 변경 - T4 GPU\n","if torch.cuda.is_available():\n","    DEVICE = torch.device('cuda')\n","else:\n","    DEVICE = torch.device('cpu')\n","print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"],"metadata":{"id":"k6bdnbKmK-ZC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 32\n","EPOCHS = 10"],"metadata":{"id":"mh9UvwnlK-3G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = datasets.CIFAR10(root = \"../data/CIFAR_10\",\n","                                  train = True,\n","                                  download = True,\n","                                  transform = transforms.Compose([\n","                                    transforms.RandomHorizontalFlip(),\n","                                    transforms.ToTensor(),\n","                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n","\n","test_dataset = datasets.CIFAR10(root = \"../data/CIFAR_10\",\n","                                train = False,\n","                                transform = transforms.Compose([\n","                                    transforms.RandomHorizontalFlip(),\n","                                    transforms.ToTensor(),\n","                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n","\n","train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n","                                            batch_size = BATCH_SIZE,\n","                                            shuffle = True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n","                                          batch_size = BATCH_SIZE,\n","                                          shuffle = False)\n"],"metadata":{"id":"isXUeFmHBGor"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for (X_train, y_train) in train_loader:\n","    print('X_train:', X_train.size(), 'type:', X_train.type())\n","    print('y_train:', y_train.size(), 'type:', y_train.type())\n","    break"],"metadata":{"id":"FYFib1SbBGvZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pltsize = 1\n","plt.figure(figsize=(10 * pltsize, pltsize))\n","\n","for i in range(10):\n","    plt.subplot(1, 10, i + 1)\n","    plt.axis('off')\n","    plt.imshow(np.transpose(X_train[i], (1, 2, 0)))\n","    plt.title('Class: ' + str(y_train[i].item()))"],"metadata":{"id":"i6M1yW2dBG1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Question 1.\n","## Building custom ResNet model\n","\n","class BasicBlock(nn.Module):\n","    def __init__(self, in_planes, planes, stride = 1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size = 3, stride = stride, padding = 1, bias = False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size = 3, stride = 1, padding = 1, bias = False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, planes, kernel_size = 1, stride = stride, bias = False),\n","                nn.BatchNorm2d(planes))\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, num_classes = 10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 16\n","\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding = 1, bias = False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.layer1 = self._make_layer(16, 2, stride = 1)\n","        self.layer2 = self._make_layer(32, 2, stride = 2)\n","        self.layer3 = self._make_layer(64, 2, stride = 2)\n","        self.linear = nn.Linear(64, num_classes)\n","\n","    def _make_layer(self, planes, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks  - 1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(BasicBlock(self.in_planes, planes, stride))\n","            self.in_planes = planes\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = F.avg_pool2d(out, 8)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out"],"metadata":{"id":"2YS8fkBVBOu_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Question 1. Explain the code above (building custom ResNet model) in detail -- line-by-line recommended"],"metadata":{"id":"JtrlgMOov47e"}},{"cell_type":"code","source":["model = ResNet().to(DEVICE)\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","print(model)"],"metadata":{"id":"vD09VxoAptUN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, train_loader, optimizer, log_interval):\n","    model.train()\n","    for batch_idx, (image, label) in enumerate(train_loader):\n","        image = image.to(DEVICE)\n","        label = label.to(DEVICE)\n","        optimizer.zero_grad()\n","        output = model(image)\n","        loss = criterion(output, label)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % log_interval == 0:\n","            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n","                epoch, batch_idx * len(image),\n","                len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n","                loss.item()))"],"metadata":{"id":"4daoEj3-ptjd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","\n","    with torch.no_grad():\n","        for image, label in test_loader:\n","            image = image.to(DEVICE)\n","            label = label.to(DEVICE)\n","            output = model(image)\n","            test_loss += criterion(output, label).item()\n","            prediction = output.max(1, keepdim = True)[1]\n","            correct += prediction.eq(label.view_as(prediction)).sum().item()\n","\n","    test_loss /= (len(test_loader.dataset) / BATCH_SIZE)\n","    test_accuracy = 100. * correct / len(test_loader.dataset)\n","    return test_loss, test_accuracy"],"metadata":{"id":"_Hm7UbzGBo9A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(1, EPOCHS + 1):\n","    train(model, train_loader, optimizer, log_interval = 200)\n","    test_loss, test_accuracy = evaluate(model, test_loader)\n","    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n","        epoch, test_loss, test_accuracy))"],"metadata":{"id":"spFvoP2MBpB5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"d__LkW3VBzpe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### The End."],"metadata":{"id":"spc48rNHQnYL"}},{"cell_type":"markdown","source":["##### Please upload your Colab file @Github https://github.com/duneag2/intro-dl/tree/main/Assignment6\n","\n","*   First, make your folder by your name (e.g. seungeun)\n","*   Then upload your \"Jupyter Notebook\" file under that directory\n","\n","###### Need Help?\n","\n","\n","\n","*   Please refer to this link https://yeko90.tistory.com/entry/%ED%8C%8C%EC%9D%B4%EC%8D%AC-colab%EC%BD%94%EB%9E%A9%EC%97%90%EC%84%9C-%EC%95%95%EC%B6%95%ED%8C%8C%EC%9D%BC-%ED%92%80%EA%B8%B0 OR\n","*   Just save your Jupyter Notebook (.ipynb) file in here (colab) and upload via 'Add file' - 'Upload files' https://nthree.tistory.com/60"],"metadata":{"id":"iMNBVkjiS7D9"}},{"cell_type":"code","source":[],"metadata":{"id":"XzVGuer0S9Oh"},"execution_count":null,"outputs":[]}]}