{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 2024 Winter Introduction to Deep Learning\n","### Based on Prof. Oh's Youtube Lecture\n","https://youtube.com/playlist?list=PLvbUC2Zh5oJvByu9KL82bswYT2IKf0K1M\n","\n","> Assignment #6\n","\n","\n","*   Youtube Lecture #23-26\n","*   Written by Seungeun Lee"],"metadata":{"id":"YcXb0XLEvHns"}},{"cell_type":"markdown","source":["## 4. Semantic Segmentation w/ pre-trained Efficient-b0 based U-Net\n","*     Custom dataset: https://www.kaggle.com/datasets/intelecai/car-segmentation\n","*     Download the dataset and unzip it as always.\n","\n"],"metadata":{"id":"qM2kM5G7BYZr"}},{"cell_type":"markdown","source":["### Quick Question. What is Instance segmentation, and how it is different from Semantic Segmentation?\n","*     Hint: https://ganghee-lee.tistory.com/44"],"metadata":{"id":"qHiOhscdJe9Z"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms as T\n","import torchvision\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","\n","from PIL import Image\n","import cv2\n","import albumentations as A\n","\n","import time\n","import os\n","from tqdm import tqdm"],"metadata":{"id":"Q7_JWyTWKoyT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q segmentation-models-pytorch ## installing a special library for segmentation"],"metadata":{"id":"mh9UvwnlK-3G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchsummary import summary\n","import segmentation_models_pytorch as smp\n","\n","# 런타임 - 런타임 유형 변경 - T4 GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"wtO6d024Pey7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ROOT = 'ENTER YOUR DIRECTORY'\n","IMAGE_PATH = os.path.join(ROOT, 'images')\n","MASK_PATH = os.path.join(ROOT, 'masks')"],"metadata":{"id":"tivyzxZBPmjC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","print(len(os.listdir(IMAGE_PATH))) ## # of images\n","assert len(os.listdir(IMAGE_PATH)) == len(os.listdir(MASK_PATH)) # check of the # of images and # of masks are the same\n","# If not, assertion error comes out, and remaining shells & commands will not be executed"],"metadata":{"id":"isXUeFmHBGor"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_classes = 5 ## there are 5 classes - check the Kaggle website (background, car, wheel, light, and windows)\n","\n","def create_df():\n","    name = []\n","    for dirname, _, filenames in os.walk(IMAGE_PATH):\n","        for filename in filenames:\n","            name.append(filename.split('.')[0])\n","\n","    return pd.DataFrame({'id': name}, index = np.arange(0, len(name)))\n","\n","df = create_df()\n","print('Total Images: ', len(df))"],"metadata":{"id":"FYFib1SbBGvZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Spliting data\n","X_train, X_val = train_test_split(df['id'][:100].values, train_size=0.8, random_state=19) # For now, let's just use 100 images\n","\n","print('Train Size   : ', len(X_train))\n","print('Val Size     : ', len(X_val))"],"metadata":{"id":"i6M1yW2dBG1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img = Image.open(IMAGE_PATH + df['id'][50] + '.png')\n","mask = Image.open(MASK_PATH + df['id'][50] + '.png')\n","print('Image Size', np.asarray(img).shape)\n","print('Mask Size', np.asarray(mask).shape)\n","\n","\n","plt.imshow(img)\n","plt.imshow(mask, alpha=0.6)\n","plt.title('Picture with Mask Appplied') ## Randomly choose one sample\n","plt.show()"],"metadata":{"id":"i2lmLeXVQmuX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CarDataset(Dataset):\n","\n","    def __init__(self, img_path, mask_path, X, mean, std, transform=None, patch=False):\n","        self.img_path = img_path\n","        self.mask_path = mask_path\n","        self.X = X\n","        self.transform = transform\n","        self.patches = patch\n","        self.mean = mean\n","        self.std = std\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        img = cv2.imread(self.img_path + self.X[idx] + '.png')\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        mask = cv2.imread(self.mask_path + self.X[idx] + '.png', cv2.IMREAD_GRAYSCALE)\n","\n","        if self.transform is not None:\n","            aug = self.transform(image=img, mask=mask)\n","            img = Image.fromarray(aug['image'])\n","            mask = aug['mask']\n","\n","        if self.transform is None:\n","            img = Image.fromarray(img)\n","\n","        t = T.Compose([T.ToTensor(), T.Normalize(self.mean, self.std)])\n","        img = t(img)\n","        mask = torch.from_numpy(mask).long()\n","\n","        if self.patches:\n","            img, mask = self.tiles(img, mask)\n","\n","        return img, mask\n","\n","    def tiles(self, img, mask):\n","\n","        img_patches = img.unfold(1, 512, 512).unfold(2, 768, 768)\n","        img_patches  = img_patches.contiguous().view(3,-1, 512, 768)\n","        img_patches = img_patches.permute(1,0,2,3)\n","\n","        mask_patches = mask.unfold(0, 512, 512).unfold(1, 768, 768)\n","        mask_patches = mask_patches.contiguous().view(-1, 512, 768)\n","\n","        return img_patches, mask_patches"],"metadata":{"id":"2YS8fkBVBOu_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean=[0.485, 0.456, 0.406]\n","std=[0.229, 0.224, 0.225]\n","\n","t_train = A.Compose([A.Resize(256, 256, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(), A.VerticalFlip(),\n","                     A.GridDistortion(p=0.2), A.RandomBrightnessContrast((0,0.5),(0,0.5)),\n","                     A.GaussNoise()])\n","\n","t_val = A.Compose([A.Resize(256, 256, interpolation=cv2.INTER_NEAREST)])\n","\n","#datasets\n","train_set = CarDataset(IMAGE_PATH, MASK_PATH, X_train, mean, std, t_train, patch=False)\n","val_set = CarDataset(IMAGE_PATH, MASK_PATH, X_val, mean, std, t_val, patch=False)\n","\n","#dataloader\n","batch_size= 3\n","\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"E40G6Z8KCrHF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = smp.Unet('efficientnet-b0', encoder_weights='imagenet', classes=5, activation=None, encoder_depth=5)"],"metadata":{"id":"vD09VxoAptUN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model)"],"metadata":{"id":"4daoEj3-ptjd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pixel_accuracy(output, mask):\n","    with torch.no_grad():\n","        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n","        correct = torch.eq(output, mask).int()\n","        accuracy = float(correct.sum()) / float(correct.numel())\n","    return accuracy"],"metadata":{"id":"_Hm7UbzGBo9A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mIoU(pred_mask, mask, smooth=1e-10, n_classes=5):\n","    with torch.no_grad():\n","        pred_mask = F.softmax(pred_mask, dim=1)\n","        pred_mask = torch.argmax(pred_mask, dim=1)\n","        pred_mask = pred_mask.contiguous().view(-1)\n","        mask = mask.contiguous().view(-1)\n","\n","        iou_per_class = []\n","        for clas in range(0, n_classes): #loop per pixel class\n","            true_class = pred_mask == clas\n","            true_label = mask == clas\n","\n","            if true_label.long().sum().item() == 0: #no exist label in this loop\n","                iou_per_class.append(np.nan)\n","            else:\n","                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n","                union = torch.logical_or(true_class, true_label).sum().float().item()\n","\n","                iou = (intersect + smooth) / (union +smooth)\n","                iou_per_class.append(iou)\n","        return np.nanmean(iou_per_class)"],"metadata":{"id":"spFvoP2MBpB5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","import numpy as np\n","\n","def dice(pred_mask, mask, smooth=1e-10, n_classes=5):\n","    with torch.no_grad():\n","        pred_mask_softmax = F.softmax(pred_mask, dim=1)\n","        pred_mask_argmax = torch.argmax(pred_mask_softmax, dim=1)\n","        pred_mask_flatten = pred_mask_argmax.contiguous().view(-1)\n","        mask_flatten = mask.contiguous().view(-1)\n","\n","        dice_per_class = []\n","\n","        for clas in range(0, n_classes):  # loop per pixel class\n","            true_class = pred_mask_flatten == clas\n","            true_label = mask_flatten == clas\n","\n","            if true_label.long().sum().item() == 0:  # no exist label in this loop\n","                dice_per_class.append(np.nan)\n","            else:\n","                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n","                dice = (2 * intersect + smooth) / (true_class.sum().float() + true_label.sum().float() + smooth)\n","                dice_per_class.append(dice)\n","\n","        return np.nanmean(dice_per_class)"],"metadata":{"id":"zF2-GHWZRGj2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Quick Question. What's (1) pixel accuracy, (2) mIOU, and (3) Dice score? Google it and write your own answer.\n"],"metadata":{"id":"CDO5k-L5FmRc"}},{"cell_type":"code","source":["def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']\n","\n","def fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler, patch=False):\n","    torch.cuda.empty_cache()\n","    train_losses = []\n","    test_losses = []\n","    val_iou = []; val_dice = []; val_acc = []\n","    train_iou = []; train_dice = []; train_acc = []\n","    lrs = []\n","    min_loss = np.inf\n","    decrease = 1 ; not_improve=0\n","\n","    model.to(device)\n","    fit_time = time.time()\n","    for e in range(epochs):\n","        since = time.time()\n","        running_loss = 0\n","        iou_score = 0\n","        dice_score = 0\n","        accuracy = 0\n","        #training loop\n","        model.train()\n","        for i, data in enumerate(tqdm(train_loader)):\n","            #training phase\n","            image_tiles, mask_tiles = data\n","            if patch:\n","                bs, n_tiles, c, h, w = image_tiles.size()\n","\n","                image_tiles = image_tiles.view(-1,c, h, w)\n","                mask_tiles = mask_tiles.view(-1, h, w)\n","\n","            image = image_tiles.to(device); mask = mask_tiles.to(device);\n","            #forward\n","            output = model(image)\n","            loss = criterion(output, mask)\n","            #evaluation metrics\n","            iou_score += mIoU(output, mask)\n","            dice_score += dice(output, mask)\n","            accuracy += pixel_accuracy(output, mask)\n","            #backward\n","            loss.backward()\n","            optimizer.step() #update weight\n","            optimizer.zero_grad() #reset gradient\n","\n","            #step the learning rate\n","            lrs.append(get_lr(optimizer))\n","            scheduler.step()\n","\n","            running_loss += loss.item()\n","\n","        else:\n","            model.eval()\n","            test_loss = 0\n","            test_accuracy = 0\n","            val_iou_score = 0\n","            val_dice_score = 0\n","            #validation loop\n","            with torch.no_grad():\n","                for i, data in enumerate(tqdm(val_loader)):\n","                    #reshape to 9 patches from single image, delete batch size\n","                    image_tiles, mask_tiles = data\n","\n","                    if patch:\n","                        bs, n_tiles, c, h, w = image_tiles.size()\n","\n","                        image_tiles = image_tiles.view(-1,c, h, w)\n","                        mask_tiles = mask_tiles.view(-1, h, w)\n","\n","                    image = image_tiles.to(device); mask = mask_tiles.to(device);\n","                    output = model(image)\n","                    #evaluation metrics\n","                    val_iou_score +=  mIoU(output, mask)\n","                    val_dice_score += dice(output, mask)\n","                    test_accuracy += pixel_accuracy(output, mask)\n","                    #loss\n","                    loss = criterion(output, mask)\n","                    test_loss += loss.item()\n","\n","            #calculatio mean for each batch\n","            train_losses.append(running_loss/len(train_loader))\n","            test_losses.append(test_loss/len(val_loader))\n","\n","\n","            if min_loss > (test_loss/len(val_loader)):\n","                print('Loss Decreasing.. {:.3f} >> {:.3f} '.format(min_loss, (test_loss/len(val_loader))))\n","                min_loss = (test_loss/len(val_loader))\n","                decrease += 1\n","                if decrease % 5 == 0:\n","                    print('saving model...')\n","#                     torch.save(model, 'Unet-Efficient_IoU-{:.3f}-femur1.pt'.format(val_iou_score/len(val_loader)))\n","\n","            if (test_loss/len(val_loader)) > min_loss:\n","                not_improve += 1\n","                min_loss = (test_loss/len(val_loader))\n","                print(f'Loss Not Decrease for {not_improve} time')\n","                if not_improve == 7:\n","                    print('Loss not decrease for 7 times, Stop Training')\n","                    break\n","\n","            #iou\n","            val_iou.append(val_iou_score/len(val_loader))\n","            train_iou.append(iou_score/len(train_loader))\n","            val_dice.append(val_dice_score/len(val_loader))\n","            train_dice.append(dice_score/len(train_loader))\n","            train_acc.append(accuracy/len(train_loader))\n","            val_acc.append(test_accuracy/ len(val_loader))\n","            print(\"Epoch:{}/{}..\".format(e+1, epochs),\n","                  \"Train Loss: {:.3f}..\".format(running_loss/len(train_loader)),\n","                  \"Val Loss: {:.3f}..\".format(test_loss/len(val_loader)),\n","                  \"Train mIoU:{:.3f}..\".format(iou_score/len(train_loader)),\n","                  \"Val mIoU: {:.3f}..\".format(val_iou_score/len(val_loader)),\n","                  \"Train dice:{:.3f}..\".format(dice_score/len(train_loader)),\n","                  \"Val dice:{:.3f}..\".format(val_dice_score/len(val_loader)),\n","                  \"Train Acc:{:.3f}..\".format(accuracy/len(train_loader)),\n","                  \"Val Acc:{:.3f}..\".format(test_accuracy/len(val_loader)),\n","                  \"Time: {:.2f}m\".format((time.time()-since)/60))\n","\n","    history = {'train_loss' : train_losses, 'val_loss': test_losses,\n","               'train_miou' :train_iou, 'val_miou':val_iou,\n","               'train_dice' :train_dice, 'val_dice':val_dice,\n","               'train_acc' :train_acc, 'val_acc':val_acc,\n","               'lrs': lrs}\n","    print('Total time: {:.2f} m' .format((time.time()- fit_time)/60))\n","    return history"],"metadata":{"id":"lY-MukEwRWnW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_lr = 1e-3\n","epoch = 30\n","weight_decay = 1e-4\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n","sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch,\n","                                            steps_per_epoch=len(train_loader))\n","\n","history = fit(epoch, model, train_loader, val_loader, criterion, optimizer, sched)\n"],"metadata":{"id":"HFyThDgTRa-O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model, 'car-segmentation-unet-1.pt')"],"metadata":{"id":"Wp7zCKvURfKv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_loss(history):\n","    plt.plot(history['val_loss'], label='val', marker='o')\n","    plt.plot( history['train_loss'], label='train', marker='o')\n","    plt.title('Loss per epoch'); plt.ylabel('loss');\n","    plt.xlabel('epoch')\n","    plt.legend(), plt.grid()\n","    plt.show()\n","\n","def plot_score(history):\n","    plt.plot(history['train_miou'], label='train_mIoU', marker='*')\n","    plt.plot(history['val_miou'], label='val_mIoU',  marker='*')\n","    plt.title('Score per epoch'); plt.ylabel('mean IoU')\n","    plt.xlabel('epoch')\n","    plt.legend(), plt.grid()\n","    plt.show()\n","\n","def plot_acc(history):\n","    plt.plot(history['train_acc'], label='train_accuracy', marker='*')\n","    plt.plot(history['val_acc'], label='val_accuracy',  marker='*')\n","    plt.title('Accuracy per epoch'); plt.ylabel('Accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(), plt.grid()\n","    plt.show()\n","\n","def plot_dice(history):\n","    plt.plot(history['train_dice'], label='train_dice', marker='*')\n","    plt.plot(history['val_dice'], label='val_dice',  marker='*')\n","    plt.title('dice per epoch'); plt.ylabel('dice')\n","    plt.xlabel('epoch')\n","    plt.legend(), plt.grid()\n","    plt.show()"],"metadata":{"id":"heEkHYAARlzu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_loss(history)\n","plot_score(history)\n","plot_acc(history)\n","plot_dice(history)"],"metadata":{"id":"XgPYOm6QRlvG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CarDataset(Dataset):\n","\n","    def __init__(self, img_path, mask_path, X, transform=None):\n","        self.img_path = img_path\n","        self.mask_path = mask_path\n","        self.X = X\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        img = cv2.imread(self.img_path + self.X[idx] + '.png')\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        mask = cv2.imread(self.mask_path + self.X[idx] + '.png', cv2.IMREAD_GRAYSCALE)\n","\n","        if self.transform is not None:\n","            aug = self.transform(image=img, mask=mask)\n","            img = Image.fromarray(aug['image'])\n","            mask = aug['mask']\n","\n","        if self.transform is None:\n","            img = Image.fromarray(img)\n","\n","        mask = torch.from_numpy(mask).long()\n","\n","        return img, mask\n","\n","\n","t_test = A.Resize(256, 256, interpolation=cv2.INTER_NEAREST)\n","test_set = CarDataset(IMAGE_PATH, MASK_PATH, X_val, transform=t_test)"],"metadata":{"id":"FW2cU0bxRlrE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_image_mask_miou(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n","    model.eval()\n","    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n","    image = t(image)\n","    model.to(device); image=image.to(device)\n","    mask = mask.to(device)\n","    with torch.no_grad():\n","\n","        image = image.unsqueeze(0)\n","        mask = mask.unsqueeze(0)\n","        mask2 = mask.cpu()\n","\n","        output = model(image)\n","        score = mIoU(output, mask)\n","        masked = torch.argmax(output, dim=1)\n","        masked = masked.cpu().squeeze(0)\n","\n","\n","    return masked, score"],"metadata":{"id":"kwoAUFcMRllM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_image_mask_pixel(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n","    model.eval()\n","    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n","    image = t(image)\n","    model.to(device); image=image.to(device)\n","    mask = mask.to(device)\n","    with torch.no_grad():\n","\n","        image = image.unsqueeze(0)\n","        mask = mask.unsqueeze(0)\n","\n","        output = model(image)\n","        acc = pixel_accuracy(output, mask)\n","        masked = torch.argmax(output, dim=1)\n","        masked = masked.cpu().squeeze(0)\n","    return masked, acc"],"metadata":{"id":"-opUuRufRldt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image, mask = test_set[3]\n","pred_mask, score = predict_image_mask_miou(model, image, mask)"],"metadata":{"id":"XwuI_ecmR45c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def miou_score(model, test_set):\n","    score_iou = []\n","    for i in tqdm(range(len(test_set))):\n","        img, mask = test_set[i]\n","        pred_mask, score = predict_image_mask_miou(model, img, mask)\n","        score_iou.append(score)\n","    return score_iou\n","\n","mob_miou = miou_score(model, test_set)"],"metadata":{"id":"7iO8W9QIR8tY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pixel_acc(model, test_set):\n","    accuracy = []\n","    for i in tqdm(range(len(test_set))):\n","        img, mask = test_set[i]\n","        pred_mask, acc = predict_image_mask_pixel(model, img, mask)\n","        accuracy.append(acc)\n","    return accuracy\n","\n","mob_acc = pixel_acc(model, test_set)"],"metadata":{"id":"LqTnRLPoR8ni"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20,10))\n","ax1.imshow(image)\n","ax1.set_title('Input');\n","ax1.set_axis_off()\n","\n","\n","ax2.imshow(mask)\n","ax2.set_title('Ground truth')\n","ax2.set_axis_off()\n","\n","ax3.imshow(pred_mask)\n","ax3.set_title('UNet-EfficientNet-b0 | IoU {:.3f}'.format(score))\n","ax3.set_axis_off()"],"metadata":{"id":"NhMLrhYkR8iL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"K7KOfbKQR8bc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Question 1. Write a brief explanation of the entire code. Just try to get the feel for this file. ChatGPT allowed!"],"metadata":{"id":"IubWV7XkFn4h"}},{"cell_type":"markdown","source":["### The End."],"metadata":{"id":"spc48rNHQnYL"}},{"cell_type":"markdown","source":["##### Please upload your Colab file @Github https://github.com/duneag2/intro-dl/tree/main/Assignment6\n","\n","*   First, make your folder by your name (e.g. seungeun)\n","*   Then upload your \"Jupyter Notebook\" file under that directory\n","\n","###### Need Help?\n","\n","\n","\n","*   Please refer to this link https://yeko90.tistory.com/entry/%ED%8C%8C%EC%9D%B4%EC%8D%AC-colab%EC%BD%94%EB%9E%A9%EC%97%90%EC%84%9C-%EC%95%95%EC%B6%95%ED%8C%8C%EC%9D%BC-%ED%92%80%EA%B8%B0 OR\n","*   Just save your Jupyter Notebook (.ipynb) file in here (colab) and upload via 'Add file' - 'Upload files' https://nthree.tistory.com/60"],"metadata":{"id":"iMNBVkjiS7D9"}},{"cell_type":"code","source":[],"metadata":{"id":"XzVGuer0S9Oh"},"execution_count":null,"outputs":[]}]}