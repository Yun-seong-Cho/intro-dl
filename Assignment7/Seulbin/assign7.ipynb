{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Recurrent Neural Networ [RNN]"
      ],
      "metadata": {
        "id": "5iLwOOukcdUS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nw4UxtcKcZqT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 5\n",
        "hidden_size = 8"
      ],
      "metadata": {
        "id": "D3YjHVTlcmy3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (batch_size, time_steps, input_size)\n",
        "inputs = torch.Tensor(1, 10, 5)"
      ],
      "metadata": {
        "id": "-rpnhqAnvd7C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cell = nn.RNN(input_size, hidden_size, batch_first=True) # defines the RNN architecture\n",
        "#batch_first = True -> indicates that the first dimensionstands for the batch size\n",
        "#if False, the input should be (10, 5), i,e. (time_steps, input_size), getting rid of the batch_size"
      ],
      "metadata": {
        "id": "SOGkRolIvmV_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs, _status = cell(inputs)"
      ],
      "metadata": {
        "id": "m3_bPBwfwwiB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.shape) #hidden_state of every time step (8-dim hidden_state for 10 time steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTvPKHJqxNhF",
        "outputId": "a9cb5550-6557-4ad7-c37c-f7498b931b34"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(_status.shape) # hidden_state of the final layer only (8-dim hidden_state for 1 time step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCrOG3vSxiBf",
        "outputId": "06c15af5-ae50-49e5-97a4-ec29b2b98f71"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Deeper RNN\n",
        "inputs2 = torch.Tensor(1, 10, 5)\n",
        "cell2 = nn.RNN(input_size = 5, hidden_size = 8, num_layers = 2, batch_first=True) # num_layers = 2 -> deeper RNN (default: 1)\n",
        "outputs2, _status2 = cell2(inputs2)\n",
        "print(outputs2.shape)\n",
        "print(_status2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxQYXif9xxsp",
        "outputId": "7ff582ba-e612-429f-a77d-5e5b35bb54a5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 8])\n",
            "torch.Size([2, 1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deeper RNN\n",
        "# (batch_size, time_steps, input_size)\n",
        "inputs3 = torch.Tensor(1, 10, 5)\n",
        "cell3 = nn.RNN(input_size = 5, hidden_size = 8, num_layers = 3, batch_first=True) # num_layers = 3 -> deeper RNN (default: 1)\n",
        "outputs3, _status3 = cell3(inputs3)\n",
        "print(outputs3.shape) # hidden_state of every time step (8-dim hidden_state for 10 time steps) -> only returns the last layer\n",
        "print(_status3.shape) # hidden_state of the final layer only (8-dim hidden_state for 1 time step) -> returns the output for all 3 layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjbzl-VtyqFE",
        "outputId": "0a77b2e6-cf02-46c5-8406-171f7a362530"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 8])\n",
            "torch.Size([3, 1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Long Short Term Memory [LSTM]"
      ],
      "metadata": {
        "id": "yR3Mcz9XihvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deeper LSTM -- only need to change nn.RNN into nn.LSTM\n",
        "# (batch_size, time_steps, input_size)\n",
        "inputs4 = torch.Tensor(1, 10, 5)\n",
        "cell4 = nn.LSTM(input_size = 5, hidden_size = 8, num_layers = 4, batch_first=True)\n",
        "outputs4, (h4, c4) = cell4(inputs4)\n",
        "print(outputs4.shape)\n",
        "print(h4.shape)\n",
        "print(c4.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDZEz1Q8inHj",
        "outputId": "e03612c2-a292-4ef6-fb9f-670c96e2b681"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 8])\n",
            "torch.Size([4, 1, 8])\n",
            "torch.Size([4, 1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1.\n",
        "### Write a code for LSTM having 10 internal layers (num_layers = 10) and change the input size into (5, 50, 5). Please stick to the format provided. Check if the size of the output, hidden, and cell state are calculated properly."
      ],
      "metadata": {
        "id": "6KlRspLYmjVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs5 = torch.Tensor(5, 50, 5)\n",
        "cell5 = nn.LSTM(input_size = 5, hidden_size = 8, num_layers = 10, batch_first=True)\n",
        "outputs5, (h5, c5) = cell5(inputs5)\n",
        "print(outputs5.shape)\n",
        "print(h5.shape)\n",
        "print(c5.shape)"
      ],
      "metadata": {
        "id": "6ZsFXOxImmTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a984415-7824-4590-b424-a5a975992bc3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 50, 8])\n",
            "torch.Size([10, 5, 8])\n",
            "torch.Size([10, 5, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2. Describe the limitations of (Vanilla) RNN and how LSTM overcomes these limitations.\n",
        "\n",
        "Limitations of RNN\n",
        "\n",
        "(1) Vanishing Gradient Problem: During backpropagation, gradients diminish, making it challenging for the model to remember information from earlier time steps.\n",
        "\n",
        "(2) Exploding Gradient Problem: Gradients grow rapidly during backpropagation, leading to unstable and unpredictable training\n",
        "\n",
        "(3) Short-Term Memory: RNN struggle with maintaining information over longer sequences. This limitation makes it difficult for RNNs to learn patterns in data with extended dependencies.\n",
        "\n",
        "How LSTM overcomes these limitations\n",
        "\n",
        "(1) Gate Mechanisms: LSTM uses gate mechanisms to control the flow of information through the cell state. This allows the model to selectively pass and store information, preventing unnecessary data loss and facilitating the learning of long-term dependencies\n",
        "\n",
        "(2) Cell state: It enables LSTMs to maintain information over longer periods. The cell state acts as a conveyor belt, allowing information to flow between cells, ensuring the retnetion of crucial information for extended sequences\n",
        "\n",
        "(3) Forget Gate: it learns what information to discard from the cell state. This gate allows the model to forget irrelevant details, keeping the cell state focused on important information and imporving the model's ability to capture meaningful patterns\n"
      ],
      "metadata": {
        "id": "qd-3rJXGNbtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Gated Recurrent Unit [GRU]"
      ],
      "metadata": {
        "id": "NSE6wQmCPjDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3.\n",
        "Write a code for GRU having 5 internal layers (num_layers = 5) and change the input size into (3, 45, 7). (Change the input_size adequately) Please stick to the format provided. Check if the size of output and hidden state are calculated properly."
      ],
      "metadata": {
        "id": "hlYbRawKPjAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs6 = torch.Tensor(3, 45, 7)\n",
        "cell6 = nn.GRU(input_size = 7, hidden_size = 8, num_layers = 5, batch_first=True)\n",
        "outputs6, _status6 = cell6(inputs6)\n",
        "print(outputs6.shape)\n",
        "print(_status6.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJYLlwvaNVeZ",
        "outputId": "c8b23b68-4c08-4e90-d113-932b6e707bcb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 45, 8])\n",
            "torch.Size([5, 3, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. On your Own\n",
        "\n",
        "### **Question 4. Choose one or two from the following documents:**\n",
        "\n",
        "\n",
        "*    **News topic Classification with RNN:** https://glanceyes.com/entry/PyTorch%EB%A1%9C-RNN-%EB%AA%A8%EB%8D%B8-%EA%B5%AC%ED%98%84%ED%95%B4%EB%B3%B4%EA%B8%B0-AG-NEWS-%EB%89%B4%EC%8A%A4-%EA%B8%B0%EC%82%AC-%EC%A3%BC%EC%A0%9C-%EB%B6%84%EB%A5%98\n",
        "*    **NAVER Movie Review Classification with LSTM:** https://wikidocs.net/217687\n",
        "*   **IMDB Review Classification with GRU:** https://wikidocs.net/217083\n",
        "\n",
        "#### Read it and run the whole code. Write a simplified explanation for each cell.\n"
      ],
      "metadata": {
        "id": "GTNZmrNtQ0Ly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU 이용한 IMDB 리뷰 분류하기\n",
        "\n",
        "### 1. 데이터로드 및 단어 토큰화"
      ],
      "metadata": {
        "id": "Y2UwCr1lYQ-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np #데이터 조작 및 수학/통계 연산을 위한 Pandas와 Numpy 라이브러리\n",
        "import matplotlib.pyplot as plt #Matplotlib: 데이터 시각화\n",
        "import nltk #NLTK(Natural Language Toolkit): 텍스트 처리 및 자연어 처리 작업에 유용한 함수와 도구 제공\n",
        "import torch #PyTorch: 신경망 모델 구축, 학습\n",
        "import urllib.request #Urllib: UPL을 통해 데이터를 다운로드 하거나 열기\n",
        "from tqdm import tqdm #TQDM: 루프에서 진행 상황을 시각적으로 표시\n",
        "from collections import Counter #데이터 요소의 개수 쉽게 개산\n",
        "from nltk.tokenize import word_tokenize #텍스트 토큰화\n",
        "from sklearn.model_selection import train_test_split #데이터를 훈련 및 테스트 세트로 분할"
      ],
      "metadata": {
        "id": "bXFLCzgdSZyz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt') #NLTK 라이브러리의 punkt데이터셋을 다운로드\n",
        "#punkt 데이터셋: NLTK에서 제공하는 토큰화 tokenization 모듈에 사용되는 데이터 파일\n",
        "#tokenization: 텍스트를 작은 단위로 나누는 작업 - 주로 단어 또는 문장으로 나누는 데 사용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f3Ji8CASd5y",
        "outputId": "4aced1b3-67b6-423d-999c-71bb40a28ee9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/pytorch-nlp-tutorial/main/10.%20RNN%20Text%20Classification/dataset/IMDB%20Dataset.csv\", filename=\"IMDB Dataset.csv\")\n",
        "#urllib.request.urlretrieve 함수를 사용하여 주어진 URL에서 파일을 다운로드\n",
        "#다운로드된 파일은 IMDB Dataset.csv로 저장"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPoK7axDSf20",
        "outputId": "03849e4d-c2aa-4f22-9fda-c6e100caf165"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('IMDB Dataset.csv', <http.client.HTTPMessage at 0x7beda74c1120>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('IMDB Dataset.csv') #Pandas 라이브러리 사용하여 IMDB Dataset.csv 파일을 데이터프레임으로 읽어옴\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3QeyNt4FShuz",
        "outputId": "125a484f-f8ad-42d7-8ae2-e50da4e34cb7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2124cfb5-8c63-404d-bb8e-f7b292240207\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2124cfb5-8c63-404d-bb8e-f7b292240207')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2124cfb5-8c63-404d-bb8e-f7b292240207 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2124cfb5-8c63-404d-bb8e-f7b292240207');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c2121043-706d-4420-80eb-118c7c61b259\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2121043-706d-4420-80eb-118c7c61b259')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c2121043-706d-4420-80eb-118c7c61b259 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_87aaa2d1-7a20-4c42-b1e3-d87f9792d5d8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_87aaa2d1-7a20-4c42-b1e3-d87f9792d5d8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() #데이터에 결측값이 있는지 확인\n",
        "#결측값missing values: 데이터 집합에서 어떤 값이나 정보가 비어 있는 상태. 누락된 값, 비어있는 값, 빈"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_XaC8asUQPk",
        "outputId": "1a18796d-7258-4709-f6bd-eeea6c25fde6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "reviwe 열과 sentiment 열 모두 non-null(결측값이 아닌) 데이터가 5만개로 확인되므로 결측값이 없다."
      ],
      "metadata": {
        "id": "txADICMdUspg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('결측값 여부 :',df.isnull().values.any()) #.isnull().values.any() 를 사용하여 결측값 여부 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSX7v30zU1I1",
        "outputId": "26e86de3-1a9e-43e5-efa3-acc42ea90d10"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결측값 여부 : False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'].value_counts().plot(kind='bar') #레이블이 균등한지 Bar Chart를 통해 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "hM-GCxOGVcQC",
        "outputId": "e96a2404-4381-42b9-fc37-28f68962933b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('레이블 개수') #레이블의 실제 개수 확인\n",
        "print(df.groupby('sentiment').size().reset_index(name='count'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2ck-BWOV6v7",
        "outputId": "7cc07a29-74be-47f1-e602-b0eb241b00f6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "레이블 개수\n",
            "  sentiment  count\n",
            "0  negative  25000\n",
            "1  positive  25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'] = df['sentiment'].replace(['positive','negative'],[1, 0]) # 현재 레이블 'positive', 'negative'를 각각 1, 0 으로 변환\n",
        "df.head() #정상 변환되었는지 확인하기 위해 상위 5개 행을 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-Hi7wTtAWsqd",
        "outputId": "dbc61863-56fc-4e80-a9e9-fd54b5db3bc5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  One of the other reviewers has mentioned that ...          1\n",
              "1  A wonderful little production. <br /><br />The...          1\n",
              "2  I thought this was a wonderful way to spend ti...          1\n",
              "3  Basically there's a family where a little boy ...          0\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0eb5667-8803-4a72-befe-b8c837f06e65\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0eb5667-8803-4a72-befe-b8c837f06e65')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0eb5667-8803-4a72-befe-b8c837f06e65 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0eb5667-8803-4a72-befe-b8c837f06e65');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a8dba236-f5e6-47c8-94c5-b3aa7b4076e4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a8dba236-f5e6-47c8-94c5-b3aa7b4076e4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a8dba236-f5e6-47c8-94c5-b3aa7b4076e4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = df['review']\n",
        "y_data = df['sentiment']\n",
        "print('영화 리뷰의 개수: {}'.format(len(X_data)))\n",
        "print('레이블의 개수: {}'.format(len(y_data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3nK8uRIW9jA",
        "outputId": "f62433e5-a6b5-4b2c-e227-aea82ceb2ac0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영화 리뷰의 개수: 50000\n",
            "레이블의 개수: 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련 데이터, 검증 데이터, 테스트 데이터로 데이터 분류\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.5, random_state=0, stratify=y_data) #훈련 데이터와 테스트 데이터 5;5\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=.2, random_state=0, stratify=y_train) #훈련 데이터를 다시 8:2로 훈련 데이터와 검증 데이터로 분류\n",
        "\n",
        "print('--------훈련 데이터의 비율-----------')\n",
        "print(f'부정 리뷰 = {round(y_train.value_counts()[0]/len(y_train) * 100,3)}%')\n",
        "print(f'긍정 리뷰 = {round(y_train.value_counts()[1]/len(y_train) * 100,3)}%')\n",
        "print('--------검증 데이터의 비율-----------')\n",
        "print(f'부정 리뷰 = {round(y_valid.value_counts()[0]/len(y_valid) * 100,3)}%')\n",
        "print(f'긍정 리뷰 = {round(y_valid.value_counts()[1]/len(y_valid) * 100,3)}%')\n",
        "print('--------테스트 데이터의 비율-----------')\n",
        "print(f'부정 리뷰 = {round(y_test.value_counts()[0]/len(y_test) * 100,3)}%')\n",
        "print(f'긍정 리뷰 = {round(y_test.value_counts()[1]/len(y_test) * 100,3)}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgWnIlzPXV8f",
        "outputId": "f1e5c682-246c-4d65-b288-2899331686d5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------훈련 데이터의 비율-----------\n",
            "부정 리뷰 = 50.0%\n",
            "긍정 리뷰 = 50.0%\n",
            "--------검증 데이터의 비율-----------\n",
            "부정 리뷰 = 50.0%\n",
            "긍정 리뷰 = 50.0%\n",
            "--------테스트 데이터의 비율-----------\n",
            "부정 리뷰 = 50.0%\n",
            "긍정 리뷰 = 50.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#토큰화\n",
        "def tokenize(sentences):\n",
        "  tokenized_sentences = []\n",
        "  for sent in tqdm(sentences):\n",
        "    tokenized_sent = word_tokenize(sent)\n",
        "    tokenized_sent = [word.lower() for word in tokenized_sent]\n",
        "    tokenized_sentences.append(tokenized_sent)\n",
        "  return tokenized_sentences\n",
        "\n",
        "tokenized_X_train = tokenize(X_train)\n",
        "tokenized_X_valid = tokenize(X_valid)\n",
        "tokenized_X_test = tokenize(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blgmoknnX5No",
        "outputId": "f73f7b74-86d1-4636-9ce8-cc6f8a0ed5ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20000/20000 [00:35<00:00, 568.79it/s]\n",
            "100%|██████████| 5000/5000 [00:08<00:00, 559.94it/s]\n",
            "100%|██████████| 25000/25000 [00:44<00:00, 564.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 상위 샘플 2개 출력\n",
        "for sent in tokenized_X_train[:2]:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFoA_XOMYG-m",
        "outputId": "39010dc6-c7fa-413a-d477-7720492a4894"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['have', 'you', 'ever', ',', 'or', 'do', 'you', 'have', ',', 'a', 'pet', 'who', \"'s\", 'been', 'with', 'you', 'through', 'thick', 'and', 'thin', ',', 'who', 'you', \"'d\", 'be', 'lost', 'without', ',', 'and', 'who', 'you', 'love', 'no', 'matter', 'what', '?', 'betcha', 'never', 'thought', 'they', 'feel', 'the', 'same', 'way', 'about', 'you', '!', '<', 'br', '/', '>', '<', 'br', '/', '>', 'wonderful', ',', 'wonderful', 'family', 'film', '.', 'if', 'you', 'have', 'a', 'soft', 'spot', 'for', 'animals', ',', 'this', 'is', 'guaranteed', 'to', 'make', 'you', 'cry', 'no', 'matter', 'your', 'age', '.', 'i', 'used', 'to', 'watch', 'this', 'movie', 'all', 'the', 'time', 'when', 'i', 'was', 'a', 'little', 'kid', ',', 'and', 'i', 'find', 'that', 'now', ',', 'at', 'age', 'sixteen', ',', 'i', 'love', 'it', 'as', 'much', 'as', 'i', 'did', 'then', '.', 'i', 'could', 'never', 'decide', 'on', 'a', 'favorite', 'character', 'then', ',', 'and', 'i', 'still', 'do', \"n't\", 'think', 'i', 'can', '!', 'i', 'love', 'all', 'three', 'of', 'the', 'animals', '.', 'the', 'dialogue', 'seems', 'very', 'real', 'and', 'comfortable', ',', 'like', 'a', 'loving', ',', 'but', 'feuding', 'family', '.', 'i', 'do', 'love', 'chance', ',', 'and', 'how', 'at', 'the', 'end', 'he', 'says', 'that', 'he', 'has', 'a', 'family', 'at', 'last', '.', 'cheesy', ',', 'yes', ',', 'but', 'one', 'must', 'remember', 'that', 'this', 'is', 'meant', 'to', 'be', 'a', 'family', 'film', ',', 'and', 'it', 'fulfills', 'that', 'role', 'perfectly', '.', 'sassy', 'has', 'just', 'the', 'perfect', 'dose', 'of', '``', 'sassiness', \"''\", 'and', 'shadow', 'is', 'the', 'perfect', 'leader/role', 'model', 'to', 'the', 'young', ',', 'adventurous', 'chance.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'animals', 'way', 'outshine', 'the', 'humans', ',', 'but', 'of', 'course', 'most', 'of', 'the', 'teary', 'moments', 'are', 'to', 'be', 'had', 'during', 'an', 'interaction', 'with', 'them', '(', 'ie', '.', 'rescuing', 'molly', ',', 'and', 'the', 'end', ')', '.', 'not', 'to', 'mention', 'the', 'incredible', 'soundtrack', 'that', 'gives', 'each', 'moment', 'even', 'more', 'emotion', ',', 'and', 'an', 'accompanying', 'heart-swelling', 'feeling', '.', 'i', 'give', 'this', '9/10', '.', 'to', 'be', 'compared', 'to', '(', 'and', 'even', 'rated', 'better', 'than', ')', 'cats', 'and', 'dogs', 'and', 'babe', '.']\n",
            "['i', 'hate', 'football', '!', '!', 'i', 'hate', 'football', 'fans', '!', 'i', 'hate', 'cars', '!', 'but', 'this', 'film', 'was', 'the', 'funniest', 'thing', 'i', 'have', 'seen', 'in', 'quite', 'some', 'time', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'i', 'was', 'given', 'the', 'great', 'opportunity', 'to', 'see', 'this', 'film', 'at', 'the', 'weekend', ',', 'and', 'all', 'i', 'have', 'to', 'say', 'is', 'i', 'laughed', 'till', 'i', 'cried', ',', 'and', 'when', 'is', 'it', 'going', 'to', 'be', 'available', 'in', 'the', 'uk', 'and', 'denmark', '.', 'girls', ',', 'this', 'is', 'one', 'football', 'film', 'you', 'will', 'need', 'to', 'see', ',', 'its', 'hilarious', '!', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'fact', 'that', 'this', 'film', 'started', 'out', 'as', 'some', 'crazy', 'commercial', 'for', 'a', 'telephone', 'company', 'is', 'just', 'amazing', ',', 'the', 'guys', 'may', 'not', 'be', 'well', 'known', 'actors', ',', 'but', 'this', 'is', 'good', 'down', 'to', 'earth', 'real', 'humour', ',', 'with', 'real', 'people', ',', 'and', 'i', 'for', 'one', 'applaud', 'them', 'for', 'taking', 'this', 'to', 'the', 'screen.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'well', 'done', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Vocab 만들기"
      ],
      "metadata": {
        "id": "k3257zb2YaD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = []\n",
        "for sent in tokenized_X_train:\n",
        "    for word in sent:\n",
        "      word_list.append(word)\n",
        "\n",
        "word_counts = Counter(word_list) #Counter 모듈을 사용하면 현재 갖고 있는 데이터에 존재하는 단어 종류의 총 개수와 각 단어에 대해서 등장 빈도를 카운트 할 수 있음\n",
        "print('총 단어수 :', len(word_counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6aM6MY3YklC",
        "outputId": "e78716a6-6be1-4b02-bf81-b5f12a53479d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 단어수 : 100586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 데이터에서의 단어 the의 등장 횟수 :', word_counts['the'])\n",
        "print('훈련 데이터에서의 단어 love의 등장 횟수 :', word_counts['love'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exnugSXIYv7W",
        "outputId": "9cee987a-e813-4ae9-f13c-cc958d16a328"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터에서의 단어 the의 등장 횟수 : 265697\n",
            "훈련 데이터에서의 단어 love의 등장 횟수 : 4984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "print('등장 빈도수 상위 10개 단어')\n",
        "print(vocab[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9bbart1ZSiZ",
        "outputId": "86d27195-4044-42e4-d744-4b6b9f40fff3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "등장 빈도수 상위 10개 단어\n",
            "['the', ',', '.', 'a', 'and', 'of', 'to', 'is', '/', '>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 등장 빈도 수가 3회 미만인 단어들이 데이터에서 얼만큼의 비중을 차지하는 지 확인\n",
        "threshold = 3\n",
        "total_cnt = len(word_counts) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUtlN4uMZeoT",
        "outputId": "e43f978d-e076-439a-bc1f-4154bcedc2f2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 100586\n",
            "등장 빈도가 2번 이하인 희귀 단어의 수: 61877\n",
            "단어 집합에서 희귀 단어의 비율: 61.51651323245779\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.3294254426463437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "등장 빈도 2회 이하인 단어들이 절반 이상 차지하지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 매우 적은 수치인 1.32%이므로 자연어 처리에서 정수 인코딩 과정에서 배제시킴"
      ],
      "metadata": {
        "id": "n5toauIEabd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 단어 개수 중 빈도수 2이하인 단어는 제거.\n",
        "vocab_size = total_cnt - rare_cnt\n",
        "vocab = vocab[:vocab_size]\n",
        "print('단어 집합의 크기 :', len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T8Qji_BaZSY",
        "outputId": "46fb55ad-3231-463b-cdd6-13ee8fd82fc5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 38709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#정수0은 패딩을 위해서 사용하는 패딩 토큰인 <PAD>를 할당\n",
        "#정수1은 OOV(Out-Of-Vocabulary) 문제 발생 시에 모르는 단어에 정수1을 할당하는 용도인 <UNK>를 할당\n",
        "word_to_index = {}\n",
        "word_to_index['<PAD>'] = 0\n",
        "word_to_index['<UNK>'] = 1\n",
        "\n",
        "for index, word in enumerate(vocab) :\n",
        "  word_to_index[word] = index + 2\n",
        "\n",
        "vocab_size = len(word_to_index)\n",
        "print('패딩 토큰과 UNK 토큰을 고려한 단어 집합의 크기 :', vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FddA9Uzial2X",
        "outputId": "6513e9f7-de7e-4ec7-a5c7-45a3dde901d5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "패딩 토큰과 UNK 토큰을 고려한 단어 집합의 크기 : 38711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 정수 인코딩"
      ],
      "metadata": {
        "id": "4lA9eSWJa40n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#최종 단어 집합(Vocabulary)인 word_to_index를 이용하여 정수 인코딩\n",
        "#texts_to_sequences(): 주어진 데이터에서 각 단어를 word_to_index에 맵핑된 정수로 변환\n",
        "#word_to_index에 존재하지 않는 단어가 등장한 경우에는 정수 1 부여\n",
        "def texts_to_sequences(tokenized_X_data, word_to_index):\n",
        "  encoded_X_data = []\n",
        "  for sent in tokenized_X_data:\n",
        "    index_sequences = []\n",
        "    for word in sent:\n",
        "      try:\n",
        "          index_sequences.append(word_to_index[word])\n",
        "      except KeyError:\n",
        "          index_sequences.append(word_to_index['<UNK>'])\n",
        "    encoded_X_data.append(index_sequences)\n",
        "  return encoded_X_data\n",
        "\n",
        "encoded_X_train = texts_to_sequences(tokenized_X_train, word_to_index)\n",
        "encoded_X_valid = texts_to_sequences(tokenized_X_valid, word_to_index)\n",
        "encoded_X_test = texts_to_sequences(tokenized_X_test, word_to_index)"
      ],
      "metadata": {
        "id": "7JW8vDl_a3st"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 상위 샘플 2개 출력\n",
        "for sent in encoded_X_train[:2]:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8kPVkl5bP9V",
        "outputId": "8c3d13b3-5ecc-4b97-9685-eb1dd7cb6181"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[38, 29, 140, 3, 52, 54, 29, 38, 3, 5, 3406, 47, 19, 95, 22, 29, 161, 4059, 6, 1741, 3, 47, 29, 293, 39, 469, 218, 3, 6, 47, 29, 134, 71, 532, 61, 59, 25184, 130, 214, 44, 249, 2, 189, 114, 58, 29, 41, 12, 13, 10, 11, 12, 13, 10, 11, 384, 3, 384, 253, 26, 4, 57, 29, 38, 5, 2280, 1587, 23, 1477, 3, 17, 9, 5775, 8, 111, 29, 1440, 71, 532, 141, 677, 4, 16, 343, 8, 126, 17, 24, 43, 2, 75, 63, 16, 20, 5, 137, 538, 3, 6, 16, 172, 18, 164, 3, 42, 677, 12075, 3, 16, 134, 14, 21, 89, 21, 16, 83, 110, 4, 16, 94, 130, 1124, 30, 5, 494, 121, 110, 3, 6, 16, 145, 54, 31, 120, 16, 73, 41, 16, 134, 43, 301, 7, 2, 1477, 4, 2, 425, 204, 66, 168, 6, 3964, 3, 50, 5, 1961, 3, 25, 19699, 253, 4, 16, 54, 134, 580, 3, 6, 105, 42, 2, 152, 36, 544, 18, 36, 55, 5, 253, 42, 247, 4, 933, 3, 421, 3, 25, 40, 227, 407, 18, 17, 9, 965, 8, 39, 5, 253, 26, 3, 6, 14, 17326, 18, 233, 872, 4, 8000, 55, 53, 2, 416, 4967, 7, 33, 1, 32, 6, 2669, 9, 2, 416, 1, 2144, 8, 2, 208, 3, 8988, 13008, 12, 13, 10, 11, 12, 13, 10, 11, 2, 1477, 114, 1, 2, 1732, 3, 25, 7, 276, 103, 7, 2, 25185, 404, 35, 8, 39, 80, 305, 46, 3778, 22, 112, 28, 6428, 4, 13009, 5279, 3, 6, 2, 152, 27, 4, 34, 8, 727, 2, 1055, 713, 18, 398, 256, 539, 70, 65, 1375, 3, 6, 46, 8753, 1, 546, 4, 16, 215, 17, 2959, 4, 8, 39, 1079, 8, 28, 6, 70, 1482, 143, 92, 27, 4610, 6, 2299, 6, 5706, 4]\n",
            "[16, 735, 2344, 41, 41, 16, 735, 2344, 467, 41, 16, 735, 1903, 41, 25, 17, 26, 20, 2, 1588, 165, 16, 38, 128, 15, 198, 62, 75, 4, 12, 13, 10, 11, 12, 13, 10, 11, 16, 20, 360, 2, 100, 1359, 8, 77, 17, 26, 42, 2, 2394, 3, 6, 43, 16, 38, 8, 147, 9, 16, 1445, 2395, 16, 3268, 3, 6, 63, 9, 14, 184, 8, 39, 1320, 15, 2, 2382, 6, 9728, 4, 520, 3, 17, 9, 40, 2344, 26, 29, 97, 354, 8, 77, 3, 109, 604, 41, 12, 13, 10, 11, 12, 13, 10, 11, 2, 206, 18, 17, 26, 652, 60, 21, 62, 912, 1877, 23, 5, 7155, 1010, 9, 53, 483, 3, 2, 451, 210, 34, 39, 91, 594, 170, 3, 25, 17, 9, 64, 202, 8, 786, 168, 1155, 3, 22, 168, 102, 3, 6, 16, 23, 40, 6916, 112, 23, 628, 17, 8, 2, 4968, 12, 13, 10, 11, 12, 13, 10, 11, 91, 237, 41]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#정수 인코딩 된 결과를 역으로 복원\n",
        "#각 단어에 정수가 맵핑된 word_to_index를 반대로 만든 index_to_word를 구현해보고 첫번째 샘플에 대해 복원\n",
        "index_to_word = {}\n",
        "for key, value in word_to_index.items():\n",
        "    index_to_word[value] = key\n",
        "\n",
        "decoded_sample = [index_to_word[word] for word in encoded_X_train[0]]\n",
        "print('기존의 첫번째 샘플 :', tokenized_X_train[0])\n",
        "print('복원된 첫번째 샘플 :', decoded_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNhlP0BTbVby",
        "outputId": "b075185f-100e-458d-ec93-af4207c84564"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "기존의 첫번째 샘플 : ['have', 'you', 'ever', ',', 'or', 'do', 'you', 'have', ',', 'a', 'pet', 'who', \"'s\", 'been', 'with', 'you', 'through', 'thick', 'and', 'thin', ',', 'who', 'you', \"'d\", 'be', 'lost', 'without', ',', 'and', 'who', 'you', 'love', 'no', 'matter', 'what', '?', 'betcha', 'never', 'thought', 'they', 'feel', 'the', 'same', 'way', 'about', 'you', '!', '<', 'br', '/', '>', '<', 'br', '/', '>', 'wonderful', ',', 'wonderful', 'family', 'film', '.', 'if', 'you', 'have', 'a', 'soft', 'spot', 'for', 'animals', ',', 'this', 'is', 'guaranteed', 'to', 'make', 'you', 'cry', 'no', 'matter', 'your', 'age', '.', 'i', 'used', 'to', 'watch', 'this', 'movie', 'all', 'the', 'time', 'when', 'i', 'was', 'a', 'little', 'kid', ',', 'and', 'i', 'find', 'that', 'now', ',', 'at', 'age', 'sixteen', ',', 'i', 'love', 'it', 'as', 'much', 'as', 'i', 'did', 'then', '.', 'i', 'could', 'never', 'decide', 'on', 'a', 'favorite', 'character', 'then', ',', 'and', 'i', 'still', 'do', \"n't\", 'think', 'i', 'can', '!', 'i', 'love', 'all', 'three', 'of', 'the', 'animals', '.', 'the', 'dialogue', 'seems', 'very', 'real', 'and', 'comfortable', ',', 'like', 'a', 'loving', ',', 'but', 'feuding', 'family', '.', 'i', 'do', 'love', 'chance', ',', 'and', 'how', 'at', 'the', 'end', 'he', 'says', 'that', 'he', 'has', 'a', 'family', 'at', 'last', '.', 'cheesy', ',', 'yes', ',', 'but', 'one', 'must', 'remember', 'that', 'this', 'is', 'meant', 'to', 'be', 'a', 'family', 'film', ',', 'and', 'it', 'fulfills', 'that', 'role', 'perfectly', '.', 'sassy', 'has', 'just', 'the', 'perfect', 'dose', 'of', '``', 'sassiness', \"''\", 'and', 'shadow', 'is', 'the', 'perfect', 'leader/role', 'model', 'to', 'the', 'young', ',', 'adventurous', 'chance.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'animals', 'way', 'outshine', 'the', 'humans', ',', 'but', 'of', 'course', 'most', 'of', 'the', 'teary', 'moments', 'are', 'to', 'be', 'had', 'during', 'an', 'interaction', 'with', 'them', '(', 'ie', '.', 'rescuing', 'molly', ',', 'and', 'the', 'end', ')', '.', 'not', 'to', 'mention', 'the', 'incredible', 'soundtrack', 'that', 'gives', 'each', 'moment', 'even', 'more', 'emotion', ',', 'and', 'an', 'accompanying', 'heart-swelling', 'feeling', '.', 'i', 'give', 'this', '9/10', '.', 'to', 'be', 'compared', 'to', '(', 'and', 'even', 'rated', 'better', 'than', ')', 'cats', 'and', 'dogs', 'and', 'babe', '.']\n",
            "복원된 첫번째 샘플 : ['have', 'you', 'ever', ',', 'or', 'do', 'you', 'have', ',', 'a', 'pet', 'who', \"'s\", 'been', 'with', 'you', 'through', 'thick', 'and', 'thin', ',', 'who', 'you', \"'d\", 'be', 'lost', 'without', ',', 'and', 'who', 'you', 'love', 'no', 'matter', 'what', '?', 'betcha', 'never', 'thought', 'they', 'feel', 'the', 'same', 'way', 'about', 'you', '!', '<', 'br', '/', '>', '<', 'br', '/', '>', 'wonderful', ',', 'wonderful', 'family', 'film', '.', 'if', 'you', 'have', 'a', 'soft', 'spot', 'for', 'animals', ',', 'this', 'is', 'guaranteed', 'to', 'make', 'you', 'cry', 'no', 'matter', 'your', 'age', '.', 'i', 'used', 'to', 'watch', 'this', 'movie', 'all', 'the', 'time', 'when', 'i', 'was', 'a', 'little', 'kid', ',', 'and', 'i', 'find', 'that', 'now', ',', 'at', 'age', 'sixteen', ',', 'i', 'love', 'it', 'as', 'much', 'as', 'i', 'did', 'then', '.', 'i', 'could', 'never', 'decide', 'on', 'a', 'favorite', 'character', 'then', ',', 'and', 'i', 'still', 'do', \"n't\", 'think', 'i', 'can', '!', 'i', 'love', 'all', 'three', 'of', 'the', 'animals', '.', 'the', 'dialogue', 'seems', 'very', 'real', 'and', 'comfortable', ',', 'like', 'a', 'loving', ',', 'but', 'feuding', 'family', '.', 'i', 'do', 'love', 'chance', ',', 'and', 'how', 'at', 'the', 'end', 'he', 'says', 'that', 'he', 'has', 'a', 'family', 'at', 'last', '.', 'cheesy', ',', 'yes', ',', 'but', 'one', 'must', 'remember', 'that', 'this', 'is', 'meant', 'to', 'be', 'a', 'family', 'film', ',', 'and', 'it', 'fulfills', 'that', 'role', 'perfectly', '.', 'sassy', 'has', 'just', 'the', 'perfect', 'dose', 'of', '``', '<UNK>', \"''\", 'and', 'shadow', 'is', 'the', 'perfect', '<UNK>', 'model', 'to', 'the', 'young', ',', 'adventurous', 'chance.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'animals', 'way', '<UNK>', 'the', 'humans', ',', 'but', 'of', 'course', 'most', 'of', 'the', 'teary', 'moments', 'are', 'to', 'be', 'had', 'during', 'an', 'interaction', 'with', 'them', '(', 'ie', '.', 'rescuing', 'molly', ',', 'and', 'the', 'end', ')', '.', 'not', 'to', 'mention', 'the', 'incredible', 'soundtrack', 'that', 'gives', 'each', 'moment', 'even', 'more', 'emotion', ',', 'and', 'an', 'accompanying', '<UNK>', 'feeling', '.', 'i', 'give', 'this', '9/10', '.', 'to', 'be', 'compared', 'to', '(', 'and', 'even', 'rated', 'better', 'than', ')', 'cats', 'and', 'dogs', 'and', 'babe', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 패딩\n",
        "\n",
        "서로 다른 길이의 데이터들을 동일한 길이로 일치 시켜주는 작업"
      ],
      "metadata": {
        "id": "EStJ3RVzbnjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 패딩을 위해 훈련 데이터의 최대 길이, 평균 길이, 그리고 데이터의 길이 분포를 확인\n",
        "print('리뷰의 최대 길이 :',max(len(review) for review in encoded_X_train))\n",
        "print('리뷰의 평균 길이 :',sum(map(len, encoded_X_train))/len(encoded_X_train))\n",
        "plt.hist([len(review) for review in encoded_X_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "418eZgEibnNg",
        "outputId": "cfedf9d0-dbc4-4421-e1fd-ab3ee1ba56b7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "리뷰의 최대 길이 : 2818\n",
            "리뷰의 평균 길이 : 279.1958\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "가장 긴 샘플의 길이는 2818\n",
        "\n",
        "전체 데이터의 길이 분포는 대체적으로 약 1000내외의 길이를 가짐.\n",
        "\n",
        "모델이 처리할 수 있도록 encoded_X_train과 encoded_T_test의 모든 샘플의 길이를 특정 길이로 동일하게 맞춰줄 필요가 있음\n",
        "\n",
        "특정 길이 변수를 max_len으로 정하기"
      ],
      "metadata": {
        "id": "t_kV3cJib9kX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 샘플 중 길이가 max_len 이하인 샘플의 비율이 몇 %인지 확인하는 함수 만들기\n",
        "def below_threshold_len(max_len, nested_list):\n",
        "  count = 0\n",
        "  for sentence in nested_list:\n",
        "    if(len(sentence) <= max_len):\n",
        "        count = count + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"
      ],
      "metadata": {
        "id": "MagJT2eAb8cY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 500\n",
        "below_threshold_len(max_len, encoded_X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOent7D-chzt",
        "outputId": "11bf5896-5215-45f0-b0ba-2368959ee9e4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 중 길이가 500 이하인 샘플의 비율: 87.795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pad_sequences(): 패딩 해주는 함수, 최대길이를 정하면 해당 길이보다 긴 데이터는 뒷 부분을 잘라서 해당 길이로 맞추고, 해당 길이보다 짧은 데이터는 뒤에 0을 채워서 해당 길이의 데이터로 변환\n",
        "def pad_sequences(sentences, max_len):\n",
        "  features = np.zeros((len(sentences), max_len), dtype=int)\n",
        "  for index, sentence in enumerate(sentences):\n",
        "    if len(sentence) != 0:\n",
        "      features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
        "  return features\n",
        "\n",
        "padded_X_train = pad_sequences(encoded_X_train, max_len=max_len)\n",
        "padded_X_valid = pad_sequences(encoded_X_valid, max_len=max_len)\n",
        "padded_X_test = pad_sequences(encoded_X_test, max_len=max_len)\n",
        "\n",
        "print('훈련 데이터의 크기 :', padded_X_train.shape)\n",
        "print('검증 데이터의 크기 :', padded_X_valid.shape)\n",
        "print('테스트 데이터의 크기 :', padded_X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opkEW3skckQN",
        "outputId": "e530078c-1fdc-4f4b-a55e-8f321048576f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기 : (20000, 500)\n",
            "검증 데이터의 크기 : (5000, 500)\n",
            "테스트 데이터의 크기 : (25000, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 모델"
      ],
      "metadata": {
        "id": "xgERcTabcyZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "93GKJrGuc1Th"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"cpu와 cuda 중 다음 기기로 학습함:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT1NaWNIc2xo",
        "outputId": "9be7de71-0ad2-4700-bf13-f7ab7f21e310"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu와 cuda 중 다음 기기로 학습함: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label data를 파이토치의 텐서 타입으로 변환\n",
        "#상위 5개의 레이블 출력\n",
        "train_label_tensor = torch.tensor(np.array(y_train))\n",
        "valid_label_tensor = torch.tensor(np.array(y_valid))\n",
        "test_label_tensor = torch.tensor(np.array(y_test))\n",
        "print(train_label_tensor[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD7t1w0Nc5Xp",
        "outputId": "f4aabc83-d3ca-4a0c-809a-e7d139443f7a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU 모델을 클래스로 구현\n",
        "\n",
        "입력은 (배치 크기, 문장 길이) 크기를 가지는 텐서\n",
        "\n",
        "임베딩 층을 지나고 나면 각 단어가 임베딩 벡터로 변환되면서 (배치 크기, 문장 길이, 임베딩 벡터의 차원)으로 텐서의 크기가 변환\n",
        "\n",
        "GRU의 마지막 시점의 은닉 상태(hidden state)값을 출력층과 연결시키는 작업 필요. 이때, GRU가 출력층으로 보는 결과값의 차원은 (배치 크기, 은닉 상태의 차원)을 가져야 함.\n",
        "\n",
        "마지막 시점의 은닉 상태의 값만 전달하므로, 은닉 상태는 모든 시점(문장 길이)만큼 존재하는 것이 아니라 단 하나만 있음. 출력층은 지난 결과는 소프트 맥스 회귀를 수행하므로 (배치 크기, 분류하고자 하는 카테고리의 수)의 차원을 가짐\n",
        "\n",
        "후 각 데이터를 배치 단위로 데이터 묶음을 꺼낼 수 있는 데이터로더로 전달.\n"
      ],
      "metadata": {
        "id": "Ame7RhGseYpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 단어 벡터의 차원 = 100\n",
        "- 문장 길이 = 500\n",
        "- 배치 크기 = 32\n",
        "- 데이터 개수 = 2만\n",
        "- GRU의 은닉층의 크기 = 128\n",
        "- 분류하고자 하는 카테고리 개수 = 2개"
      ],
      "metadata": {
        "id": "jE-o43Vhe-lS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터의 변화\n",
        "\n",
        "(32, 500) => 입력 데이터의 형태 => 임베딩 층 통과 후 => (32, 500, 100) => GRU 통과 후 => (32, 128) => Softmax 출력층 통과 후 => (32, 2)"
      ],
      "metadata": {
        "id": "Xb2F3e2-fE4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super(TextClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim) # output_dim = 분류하고자하는 카테고리의 개수\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, seq_length) == (32, 500)\n",
        "        embedded = self.embedding(x)  # (batch_size, seq_length, embedding_dim) == (32, 500, 100) == (데이터의 개수, 문장길이, 단어 벡터의 차원)\n",
        "        gru_out, hidden = self.gru(embedded)  # gru_out: (batch_size, seq_length, hidden_dim), hidden: (1, batch_size, hidden_dim)\n",
        "        last_hidden = hidden.squeeze(0)  # (batch_size, hidden_dim)\n",
        "        logits = self.fc(last_hidden)  # (batch_size, output_dim)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "uIhCHuPVeK8A"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터, 검증 데이터, 테스트 데이터에 대해서 파이토치 텐서로 변환하고 배치 단위 연산을 위해 데이터로더로 변환\n",
        "encoded_train = torch.tensor(padded_X_train).to(torch.int64)\n",
        "train_dataset = torch.utils.data.TensorDataset(encoded_train, train_label_tensor)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
        "\n",
        "encoded_test = torch.tensor(padded_X_test).to(torch.int64)\n",
        "test_dataset = torch.utils.data.TensorDataset(encoded_test, test_label_tensor)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=1)\n",
        "\n",
        "encoded_valid = torch.tensor(padded_X_valid).to(torch.int64)\n",
        "valid_dataset = torch.utils.data.TensorDataset(encoded_valid, valid_label_tensor)\n",
        "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, shuffle=True, batch_size=1)"
      ],
      "metadata": {
        "id": "9U6OkToafT7Y"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_batch = len(train_dataloader)\n",
        "print('총 배치의 수 : {}'.format(total_batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Klr0kJsMfabn",
        "outputId": "68e02120-b2ea-47ed-838f-77a4a1da79cf"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 배치의 수 : 625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 객체 선언\n",
        "embedding_dim = 100\n",
        "hidden_dim = 128\n",
        "output_dim = 2\n",
        "learning_rate = 0.01\n",
        "num_epochs = 10\n",
        "\n",
        "model = TextClassifier(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMfQOXGNfdAX",
        "outputId": "ea38d2dc-64ff-46b7-fbcc-8361f9c5fc95"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextClassifier(\n",
              "  (embedding): Embedding(38711, 100)\n",
              "  (gru): GRU(100, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss() #파이토치로 자연어 처리를 하게 되면 가장 많이 사용하게 되는 손실함수\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "CCQsWD9jfkKZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. 평가 코드 작성"
      ],
      "metadata": {
        "id": "WXmBE_3hfoIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모델의 정확도 측정\n",
        "def calculate_accuracy(logits, labels):\n",
        "    # _, predicted = torch.max(logits, 1)\n",
        "    predicted = torch.argmax(logits, dim=1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    accuracy = correct / total\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "BbK9heA1frwW"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, valid_dataloader, criterion, device):\n",
        "    val_loss = 0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    model.eval() #모델을 평가모드로 설정\n",
        "    with torch.no_grad():\n",
        "        # 데이터로더로부터 배치 크기만큼의 데이터를 연속으로 로드\n",
        "        for batch_X, batch_y in valid_dataloader:\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "            # 모델의 예측값\n",
        "            logits = model(batch_X)\n",
        "\n",
        "            # 손실을 계산\n",
        "            loss = criterion(logits, batch_y)\n",
        "\n",
        "            # 정확도와 손실을 계산함\n",
        "            val_loss += loss.item()\n",
        "            val_correct += calculate_accuracy(logits, batch_y) * batch_y.size(0)\n",
        "            val_total += batch_y.size(0)\n",
        "\n",
        "    val_accuracy = val_correct / val_total\n",
        "    val_loss /= len(valid_dataloader)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "NaKY-L1VfwEK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. 학습"
      ],
      "metadata": {
        "id": "IgqrbP3xf-OV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "# Training loop\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    model.train()\n",
        "    for batch_X, batch_y in train_dataloader:\n",
        "        # Forward pass\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        # batch_X.shape == (batch_size, max_len)\n",
        "        logits = model(batch_X)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(logits, batch_y)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate training accuracy and loss\n",
        "        train_loss += loss.item()\n",
        "        train_correct += calculate_accuracy(logits, batch_y) * batch_y.size(0)\n",
        "        train_total += batch_y.size(0)\n",
        "\n",
        "    train_accuracy = train_correct / train_total\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    # Validation\n",
        "    val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
        "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "    # 검증 손실이 최소일 때 체크포인트 저장\n",
        "    if val_loss < best_val_loss:\n",
        "        print(f'Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. 체크포인트를 저장합니다.')\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_model_checkpoint.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MegFcsArgCxK",
        "outputId": "4f1773ec-0d52-4e73-a1b9-44cb1a958320"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "Train Loss: 0.6972, Train Accuracy: 0.5070\n",
            "Validation Loss: 0.6969, Validation Accuracy: 0.5012\n",
            "Validation loss improved from inf to 0.6969. 체크포인트를 저장합니다.\n",
            "Epoch 2/5:\n",
            "Train Loss: 0.6914, Train Accuracy: 0.5133\n",
            "Validation Loss: 0.6930, Validation Accuracy: 0.4998\n",
            "Validation loss improved from 0.6969 to 0.6930. 체크포인트를 저장합니다.\n",
            "Epoch 3/5:\n",
            "Train Loss: 0.6818, Train Accuracy: 0.5199\n",
            "Validation Loss: 0.6971, Validation Accuracy: 0.5076\n",
            "Epoch 4/5:\n",
            "Train Loss: 0.6364, Train Accuracy: 0.6049\n",
            "Validation Loss: 0.6469, Validation Accuracy: 0.6446\n",
            "Validation loss improved from 0.6930 to 0.6469. 체크포인트를 저장합니다.\n",
            "Epoch 5/5:\n",
            "Train Loss: 0.4360, Train Accuracy: 0.8019\n",
            "Validation Loss: 0.4225, Validation Accuracy: 0.8202\n",
            "Validation loss improved from 0.6469 to 0.4225. 체크포인트를 저장합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. 모델 로드 및 평가"
      ],
      "metadata": {
        "id": "tzsyzhIKgDww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 로드\n",
        "model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n",
        "\n",
        "# 모델을 device에 올립니다.\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XacllO3if9KR",
        "outputId": "301a7ea2-45c4-405a-b205-b4b9339ede22"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextClassifier(\n",
              "  (embedding): Embedding(38711, 100)\n",
              "  (gru): GRU(100, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 데이터에 대한 정확도와 손실 계산\n",
        "val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n",
        "\n",
        "print(f'Best model validation loss: {val_loss:.4f}')\n",
        "print(f'Best model validation accuracy: {val_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5X_Nw4mgJJl",
        "outputId": "654dfb37-aeac-4dd6-ba0d-b7072b429a35"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model validation loss: 0.4225\n",
            "Best model validation accuracy: 0.8202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터에 대한 정확도와 손실 계산\n",
        "test_loss, test_accuracy = evaluate(model, test_dataloader, criterion, device)\n",
        "\n",
        "print(f'Best model test loss: {test_loss:.4f}')\n",
        "print(f'Best model test accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeFGyFQxgKrw",
        "outputId": "8019baef-e214-42f3-b31e-fa98d69787de"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model test loss: 0.4356\n",
            "Best model test accuracy: 0.8135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. 모델 테스트"
      ],
      "metadata": {
        "id": "WiGb1rplgMvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_tag = {0 : '부정', 1 : '긍정'}\n",
        "\n",
        "def predict(text, model, word_to_index, index_to_tag):\n",
        "    # 모델 평가 모드\n",
        "    model.eval()\n",
        "\n",
        "    # 토큰화 및 정수 인코딩. OOV 문제 발생 시 <UNK> 토큰에 해당하는 인덱스 1 할당\n",
        "    tokens = word_tokenize(text)\n",
        "    token_indices = [word_to_index.get(token.lower(), 1) for token in tokens]\n",
        "\n",
        "    # 리스트를 텐서로 변경\n",
        "    input_tensor = torch.tensor([token_indices], dtype=torch.long).to(device)  # (1, seq_length)\n",
        "\n",
        "    # 모델의 예측\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)  # (1, output_dim)\n",
        "\n",
        "    # 레이블 인덱스 예측\n",
        "    _, predicted_index = torch.max(logits, dim=1)  # (1,)\n",
        "\n",
        "    # 인덱스와 매칭되는 카테고리 문자열로 변경\n",
        "    predicted_tag = index_to_tag[predicted_index.item()]\n",
        "\n",
        "    return predicted_tag"
      ],
      "metadata": {
        "id": "Bk_kJzCBgReJ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = \"This movie was just way too overrated. The fighting was not professional and in slow motion. I was expecting more from a 200 million budget movie. The little sister of T.Challa was just trying too hard to be funny. The story was really dumb as well. Don't watch this movie if you are going because others say its great unless you are a Black Panther fan or Marvels fan.\"\n",
        "\n",
        "predict(test_input, model, word_to_index, index_to_tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PMlTW97QgaVi",
        "outputId": "8f9f2667-3045-47a4-809f-b71a31ecb47b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'부정'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = \" I was lucky enough to be included in the group to see the advanced screening in Melbourne on the 15th of April, 2012. And, firstly, I need to say a big thank-you to Disney and Marvel Studios. Now, the film... how can I even begin to explain how I feel about this film? It is, as the title of this review says a 'comic book triumph'. I went into the film with very, very high expectations and I was not disappointed. Seeing Joss Whedon's direction and envisioning of the film come to life on the big screen is perfect. The script is amazingly detailed and laced with sharp wit a humor. The special effects are literally mind-blowing and the action scenes are both hard-hitting and beautifully choreographed.\"\n",
        "\n",
        "predict(test_input, model, word_to_index, index_to_tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0AqbtODwgdGP",
        "outputId": "c90e2ba4-5b7f-4925-c384-95882f7f4b70"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'긍정'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ]
}